{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to compile the facs data table from the FlowJo output (+IndexSort plugin).\n",
    ".fcs files were gated in FlowJo and well location was preserved using the IndexSort plugin. Bi-exponential transform was applied and the FACS data was exported as the transformed 'channel' tables. To preserve the well location, also the un-transformed 'scale' tables were exported. These tables are beeing merged in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = ['8227_INX_celltype_P1_003',\n",
    "          '8227_INX_celltype_P2_004',\n",
    "          '8227_INX_celltype_P3_005']\n",
    "\n",
    "path = '../data/facs_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all csv files in channel and scale folder\n",
    "files = [f for f in os.listdir(path+'channel/') if f.endswith(\".csv\")]\n",
    "fcs = ['_'.join(x.split('_')[1:-1]) for x in files]\n",
    "data = pd.DataFrame({'file': files, 'fcs': fcs, 'plate': [plates.index(p) for p in fcs]}).set_index('file')\n",
    "dfs_channel = [pd.DataFrame() for i in range(len(plates))]\n",
    "\n",
    "for f in files:\n",
    "    fj = pd.read_csv(path+'channel/{}'.format(f))\n",
    "    dfs_channel[data.loc[f, 'plate']] = dfs_channel[data.loc[f, 'plate']].append(fj)\n",
    "\n",
    "dfs_scale = [pd.DataFrame() for i in range(len(plates))]\n",
    "for f in files:\n",
    "    fj = pd.read_csv(path+'scale/{}'.format(f))\n",
    "    dfs_scale[data.loc[f, 'plate']] = dfs_scale[data.loc[f, 'plate']].append(fj)\n",
    "\n",
    "# replace the index columns with the non-transformed values from scale\n",
    "for i in range(len(dfs_channel)):\n",
    "    dfs_channel[i].loc[:, ['IdxCol', 'IdxRow', 'Time']] = dfs_scale[i].loc[:, ['IdxCol', 'IdxRow', 'Time']]\n",
    "\n",
    "# transform row index in letter and make Well column. Somehow, the IdxRow index from FJ is reversed\n",
    "for i in range(len(dfs_channel)):\n",
    "    dfs_channel[i][\"IdxRow\"] = dfs_channel[i][\"IdxRow\"].apply(\n",
    "    lambda x: [\n",
    "        \"A\",\n",
    "        \"B\",\n",
    "        \"C\",\n",
    "        \"D\",\n",
    "        \"E\",\n",
    "        \"F\",\n",
    "        \"G\",\n",
    "        \"H\",\n",
    "        \"I\",\n",
    "        \"J\",\n",
    "        \"K\",\n",
    "        \"L\",\n",
    "        \"M\",\n",
    "        \"N\",\n",
    "        \"O\",\n",
    "        \"P\",\n",
    "    ][-x]\n",
    "    )\n",
    "    dfs_channel[i][\"Well\"] = dfs_channel[i][\"IdxRow\"] + dfs_channel[i][\"IdxCol\"].astype(str)\n",
    "    dfs_channel[i] = dfs_channel[i].rename(columns={'IdxRow': 'Row', 'IdxCol': 'Column'})\n",
    "\n",
    "# save one table for each plate\n",
    "[dfs_channel[i].to_csv(path+'facs_data_P{}.txt'.format(i+1), sep='\\t', index=False) for i in range(len(dfs_channel))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
